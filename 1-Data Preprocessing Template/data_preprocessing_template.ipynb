{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Preprocessing Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing the dataset with using pandas\n",
    "datasets = pd.read_csv(\"Data.csv\")            # imported the Dataset as pandas dataframe.It includes header.\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['France', 44.0, 72000.0],\n",
       "        ['Spain', 27.0, 48000.0],\n",
       "        ['Germany', 30.0, 54000.0],\n",
       "        ['Spain', 38.0, 61000.0],\n",
       "        ['Germany', 40.0, nan],\n",
       "        ['France', 35.0, 58000.0],\n",
       "        ['Spain', nan, 52000.0],\n",
       "        ['France', 48.0, 79000.0],\n",
       "        ['Germany', 50.0, 83000.0],\n",
       "        ['France', 37.0, 67000.0]], dtype=object),\n",
       " array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Splitting the dataset to the features and label\n",
    "X = datasets.iloc[:,:-1].values            # takes all columns without last column which is label\n",
    "\n",
    "y = datasets.iloc[:, 3].values             # just takes last column according the its column's order \n",
    "                                           # ( be careful that python list sort rule begins with 0th)\n",
    "\n",
    "X,y                                        # X :all features -  y:label or target value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking Care of Missing Values    \n",
    "from  sklearn.preprocessing import Imputer                          # Imputation transformer for completing missing values(by sklearn_docs)   \n",
    "imputer = Imputer(missing_values = \"NaN\", strategy=\"mean\", axis=0)  # object is created to fill NaN variable according to the strategy. \n",
    "                                                                    # strategy can be: \"mean\",\"median\",\"most_frequent\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.0, 72000.0],\n",
       "       [27.0, 48000.0],\n",
       "       [30.0, 54000.0],\n",
       "       [38.0, 61000.0],\n",
       "       [40.0, 63777.77777777778],\n",
       "       [35.0, 58000.0],\n",
       "       [38.77777777777778, 52000.0],\n",
       "       [48.0, 79000.0],\n",
       "       [50.0, 83000.0],\n",
       "       [37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = imputer.fit(X[:,1:3])                   # fit and transform the values which are 1st and 2th columns                             \n",
    "X[:,1:3] = imputer.transform(X[:,1:3])            # all NaN values are filled with selected strategy \n",
    "\n",
    "X[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 2, 1, 0, 2, 0, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encoding Categorical Data\n",
    "from sklearn.preprocessing import LabelEncoder          # Encode labels with value between 0 and n_classes-1\n",
    "\n",
    "\n",
    "                                                        \n",
    "labelencoder_X = LabelEncoder()                            \n",
    "\n",
    "X[:,0] = labelencoder_X.fit_transform(X[:,0])           # Turns the categorical variables to the numerical values\n",
    "\n",
    "                                                       \n",
    "X[:,0]                                                  # France,Germany, Spain  are encoded with respect to 0,1,2 \n",
    "                                                        # they all are turned to the numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n",
       "        7.20000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n",
       "        4.80000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n",
       "        5.40000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
       "        6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
       "        6.37777778e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n",
       "        5.80000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n",
       "        5.20000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
       "        7.90000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.00000000e+01,\n",
       "        8.30000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
       "        6.70000000e+04]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder         # One hot encoder to perform “binarization” of the category\n",
    "                                                        # and include it as a feature to train the model.\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "X                                                       # one hot encoder creates columns for all encoded features because of binarization.\n",
    "                                                        # If not hot encoding, machine learning algorithm thinks 2>1>0,\n",
    "                                                        # so it cause some false predictions. One hot encoders occurs equal ground all of them.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "y                                     # encoded like -> no : 0 , yes : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split              \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=0)   \n",
    "\n",
    "                                    # at this stage, creates datasets for training and testing the ML model.\n",
    "                                    #  test_size parameter is preferable around 0.2 or 0.25.\n",
    "                                    # random state parameter selected a number for the getting the same result on the further splits\n",
    "                                    # some other split parameters can be important for the real case problems like \"shuffle\"... \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
       "         6.37777778e+04],\n",
       "        [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
       "         6.70000000e+04],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n",
       "         4.80000000e+04],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n",
       "         5.20000000e+04],\n",
       "        [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
       "         7.90000000e+04],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
       "         6.10000000e+04],\n",
       "        [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n",
       "         7.20000000e+04],\n",
       "        [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n",
       "         5.80000000e+04]]),\n",
       " array([[0.0e+00, 1.0e+00, 0.0e+00, 3.0e+01, 5.4e+04],\n",
       "        [0.0e+00, 1.0e+00, 0.0e+00, 5.0e+01, 8.3e+04]]),\n",
       " array([1, 1, 1, 0, 1, 0, 0, 1]),\n",
       " array([0, 0]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Scaling \n",
    "from sklearn.preprocessing import StandardScaler    # Standardization of a dataset is a common requirement \n",
    "                                                    # for many machine learning estimators:they might behave\n",
    "                                                    # badly if the individual feature do not more or less look\n",
    "                                                    # like standard normally distributed data (by sklearn_docs)\n",
    "\n",
    "sc_X = StandardScaler()                             # There are lots of scaler but we are going to use StandardScaler.\n",
    "X_train = sc_X.fit_transform(X_train)               # Scaling gives the computational speed and some algorithm\n",
    "                                                    # requires same scaled datasets on the their learning processes.\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.        ,  2.64575131, -0.77459667,  0.26306757,  0.12381479],\n",
       "        [ 1.        , -0.37796447, -0.77459667, -0.25350148,  0.46175632],\n",
       "        [-1.        , -0.37796447,  1.29099445, -1.97539832, -1.53093341],\n",
       "        [-1.        , -0.37796447,  1.29099445,  0.05261351, -1.11141978],\n",
       "        [ 1.        , -0.37796447, -0.77459667,  1.64058505,  1.7202972 ],\n",
       "        [-1.        , -0.37796447,  1.29099445, -0.0813118 , -0.16751412],\n",
       "        [ 1.        , -0.37796447, -0.77459667,  0.95182631,  0.98614835],\n",
       "        [ 1.        , -0.37796447, -0.77459667, -0.59788085, -0.48214934]]),\n",
       " array([[-1.        ,  2.64575131, -0.77459667, -1.45882927, -0.90166297],\n",
       "        [-1.        ,  2.64575131, -0.77459667,  1.98496442,  2.13981082]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
